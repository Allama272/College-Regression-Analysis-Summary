<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Obsidian Vault]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>lib\media\favicon.png</url><title>Obsidian Vault</title><link></link></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Tue, 02 Apr 2024 20:50:57 GMT</lastBuildDate><atom:link href="lib\rss.xml" rel="self" type="application/rss+xml"/><pubDate>Tue, 02 Apr 2024 20:50:54 GMT</pubDate><ttl>60</ttl><dc:creator></dc:creator><item><title><![CDATA[College Regression Analysis]]></title><description><![CDATA[ 
 <br><br>Tags: <a data-href="Computer Science" href="\Computer Science" class="internal-link" target="_self" rel="noopener">Computer Science</a> <a data-href="Math" href="\Math" class="internal-link" target="_self" rel="noopener">Math</a> <a data-href="Statistics" href="\Statistics" class="internal-link" target="_self" rel="noopener">Statistics</a> <a data-href="Regression" href="\Regression" class="internal-link" target="_self" rel="noopener">Regression</a><br>
<br><a data-href="Least-Square-Estimation-Linear-Regression" href="\zettelkasten\literature-notes\least-square-estimation-linear-regression.html" class="internal-link" target="_self" rel="noopener">Least-Square-Estimation-Linear-Regression</a>
<br><a data-href="Least-Square-Estimation-Model-Assumptions-and-Residuals" href="\zettelkasten\literature-notes\least-square-estimation-model-assumptions-and-residuals.html" class="internal-link" target="_self" rel="noopener">Least-Square-Estimation-Model-Assumptions-and-Residuals</a>
<br><a data-href="Linear-Regression-Parameter-Distribution" href="\zettelkasten\literature-notes\linear-regression-parameter-distribution.html" class="internal-link" target="_self" rel="noopener">Linear-Regression-Parameter-Distribution</a>
<br><a data-href="Linear-Regression-Sxx,Syy-Variances-Sigma-MSE-r" href="\zettelkasten\literature-notes\linear-regression-sxx,syy-variances-sigma-mse-r.html" class="internal-link" target="_self" rel="noopener">Linear-Regression-Sxx,Syy-Variances-Sigma-MSE-r</a>
<br><a data-href="Linear-Regression-SSE-SSR-SST" href="\zettelkasten\literature-notes\linear-regression-sse-ssr-sst.html" class="internal-link" target="_self" rel="noopener">Linear-Regression-SSE-SSR-SST</a>
<br><a data-href="Linear-Regression-Anova-Hypothesis-Testing" href="\zettelkasten\literature-notes\linear-regression-anova-hypothesis-testing.html" class="internal-link" target="_self" rel="noopener">Linear-Regression-Anova-Hypothesis-Testing</a>
<br><a data-href="Linear-Regression-Confidence-interval-for-parameter" href="\zettelkasten\literature-notes\linear-regression-confidence-interval-for-parameter.html" class="internal-link" target="_self" rel="noopener">Linear-Regression-Confidence-interval-for-parameter</a>
]]></description><link>zettelkasten\hub-notes\college-regression-analysis.html</link><guid isPermaLink="false">Zettelkasten/Hub Notes/College Regression Analysis.md</guid><pubDate>Tue, 02 Apr 2024 10:39:56 GMT</pubDate></item><item><title><![CDATA[Least-Square-Estimation-Linear-Regression]]></title><description><![CDATA[ 
 <br>Tags: <a data-href="Regression" href="\Regression" class="internal-link" target="_self" rel="noopener">Regression</a> <a data-href="Computer Science" href="\Computer Science" class="internal-link" target="_self" rel="noopener">Computer Science</a> <a data-href="Math" href="\Math" class="internal-link" target="_self" rel="noopener">Math</a><br><br><br><img alt="Pasted image 20240314132935.png" src="\lib\media\pasted-image-20240314132935.png" style="width: 500px; max-width: 100%;">
 We want to minimize the error/residual (), between each point and the line
<img alt="Pasted image 20240314133050.png" src="\lib\media\pasted-image-20240314133050.png" style="width: 500px; max-width: 100%;">
At first thought, we can try summing these residuals. But some of those residuals are positive (above the line), and some are negative (below the line) making the sum of the errors a smaller number than it actually is.
Thus we square each residual, then sum them all. This is called sum of square Errors (SSE)
<img alt="Pasted image 20240314133405.png" src="\lib\media\pasted-image-20240314133405.png" style="width: 500px; max-width: 100%;">
In order to minimize the error, and estimate  and  to get the best fit line<br>Imp
The LS regression line always passes through the centroid (, ) of the data
<br><br>we first isolate the error, then square the sum of the differences to get the sum of square Errors (SSE) :<br><br>
<br>We then take the partial derivative with respect to  and 
<br>Set the partial derivative = 0
<br>Solve for  and  
Tip



<br><br><br><br><br><br> Same Steps can be made with y<br>Note
note:  since it will be   
<br><br>Important
if we solved for y we would get

<br><br><img alt="Pasted image 20240317140329.png" src="\lib\media\pasted-image-20240317140329.png" style="width: 400px; max-width: 100%;">
<img alt="Pasted image 20240317140429.png" src="\lib\media\pasted-image-20240317140429.png" style="width: 650px; max-width: 100%;"><br><br><br><a data-href="College Regression Analysis" href="\zettelkasten\hub-notes\college-regression-analysis.html" class="internal-link" target="_self" rel="noopener">College Regression Analysis</a>]]></description><link>zettelkasten\literature-notes\least-square-estimation-linear-regression.html</link><guid isPermaLink="false">Zettelkasten/Literature Notes/Least-Square-Estimation-Linear-Regression.md</guid><pubDate>Tue, 02 Apr 2024 10:23:00 GMT</pubDate><enclosure url="lib\media\pasted-image-20240314132935.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240314132935.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Assumptions about the model:]]></title><description><![CDATA[ 
 <br>Tags: <a data-href="Regression" href="\Regression" class="internal-link" target="_self" rel="noopener">Regression</a> <a data-href="Data-Science" href="\Data-Science" class="internal-link" target="_self" rel="noopener">Data-Science</a><br><br>
<br> is iid
<br> normally distributed 
<br>Has constant variance  at every value of  
<br> (independent)
<br>The model has the form  
<br><br>The residuals can be written in many different forms:<br><br><br>Proof: <br><br>proof:<br><br>Remember, we proved in <a data-tooltip-position="top" aria-label="Least-Square-Estimation-Linear-Regression > Mathematically" data-href="Least-Square-Estimation-Linear-Regression#Mathematically" href="\zettelkasten\literature-notes\least-square-estimation-linear-regression.html#Mathematically" class="internal-link" target="_self" rel="noopener">least squares method (1.5)</a>

<br>proof:<br><br><br><br><a data-href="College Regression Analysis" href="\zettelkasten\hub-notes\college-regression-analysis.html" class="internal-link" target="_self" rel="noopener">College Regression Analysis</a>]]></description><link>zettelkasten\literature-notes\least-square-estimation-model-assumptions-and-residuals.html</link><guid isPermaLink="false">Zettelkasten/Literature Notes/Least-Square-Estimation-Model-Assumptions-and-Residuals.md</guid><pubDate>Tue, 02 Apr 2024 10:40:38 GMT</pubDate></item><item><title><![CDATA[Linear-Regression-Anova]]></title><description><![CDATA[ 
 <br>Tags: <a data-href="Regression" href="\Regression" class="internal-link" target="_self" rel="noopener">Regression</a> <a data-href="Data-Science" href="\Data-Science" class="internal-link" target="_self" rel="noopener">Data-Science</a><br><br>Distributions reminder

<br><br>remember when we proved <a data-tooltip-position="top" aria-label="Linear-Regression-SSE-SSR-SST" data-href="Linear-Regression-SSE-SSR-SST" href="\zettelkasten\literature-notes\linear-regression-sse-ssr-sst.html" class="internal-link" target="_self" rel="noopener">this</a>:<br><br><br>Honestly I don't fully get why the dfs have those numbers but check this if <a data-tooltip-position="top" aria-label="https://math.stackexchange.com/a/1535456" rel="noopener" class="external-link" href="https://math.stackexchange.com/a/1535456" target="_blank">interested</a>.<br><br><br>
<br>
The Anova test is used as a general test to see if there is a relation or not between the variables.
(e.g. in an ice cream shop {temperature of the day, price, day of the week} are affecting the {sales of the shop})

<br>
A second step would be using a more specific test to see which variable has what relationship.
(e.g.) a second test only between {temperature of the day} and {sales} found a strong positive relation, while a test between {day of the week} and {sales} found a weak relation ship

<br><br>
<br>We assume that the slope is 0 (horizontal line no relation) 
<br>Get the value of  from the ANOVA table
<br>Get the value of , where  =1-C.I (confidence interval) ex: if C.I=95%, then  =5% 
<br>If  reject  ( thus there is a relation)<br>
If  fail to reject  (( thus there is a no relation))
<br>Note: The bigger the  , the smaller the variance and the more accurate the estimator. (vice versa)<br><br><br><a data-href="College Regression Analysis" href="\zettelkasten\hub-notes\college-regression-analysis.html" class="internal-link" target="_self" rel="noopener">College Regression Analysis</a>]]></description><link>zettelkasten\literature-notes\linear-regression-anova-hypothesis-testing.html</link><guid isPermaLink="false">Zettelkasten/Literature Notes/Linear-Regression-Anova-Hypothesis-Testing.md</guid><pubDate>Tue, 02 Apr 2024 10:40:14 GMT</pubDate></item><item><title><![CDATA[Linear-Regression-Confidence-interval-for-parameters]]></title><description><![CDATA[ 
 <br>Tags: <a data-href="Regression" href="\Regression" class="internal-link" target="_self" rel="noopener">Regression</a> <a data-href="Data-Science" href="\Data-Science" class="internal-link" target="_self" rel="noopener">Data-Science</a><br><br>Remember from Probability 2, we had these rules:<br>confidence interval

<br>where we use + for the upper and - for lower.
<img alt="Pasted image 20240402224811.png" src="\lib\media\pasted-image-20240402224811.png" style="width: 600px; max-width: 100%;">
<img alt="Pasted image 20240402063129.png" src="\lib\media\pasted-image-20240402063129.png" style="width: 600px; max-width: 100%;"><br><br>(Refer to <a data-tooltip-position="top" aria-label="Linear-Regression-Parameter-Distribution > $ beta_{0}$ Distribution" data-href="Linear-Regression-Parameter-Distribution#$ beta_{0}$ Distribution" href="\zettelkasten\literature-notes\linear-regression-parameter-distribution.html#$_beta_{0}$_Distribution" class="internal-link" target="_self" rel="noopener">this</a>)<br><br><br><br><br> = MSE, refer to <a data-tooltip-position="top" aria-label="Linear-Regression-Sxx,Syy-Variances-Sigma-MSE-r > Estimating $ sigma {2}$ and MSE" data-href="Linear-Regression-Sxx,Syy-Variances-Sigma-MSE-r#Estimating $ sigma {2}$ and MSE" href="\zettelkasten\literature-notes\linear-regression-sxx,syy-variances-sigma-mse-r.html#Estimating_$_sigma_{2}$_and_MSE" class="internal-link" target="_self" rel="noopener">MSE and the variance</a>.<br><br>(Refer to <a data-tooltip-position="top" aria-label="Linear-Regression-Parameter-Distribution > $ beta_{0}$ Distribution" data-href="Linear-Regression-Parameter-Distribution#$ beta_{0}$ Distribution" href="\zettelkasten\literature-notes\linear-regression-parameter-distribution.html#$_beta_{0}$_Distribution" class="internal-link" target="_self" rel="noopener">this</a>)<br><br><br><br><br> = MSE, refer to <a data-tooltip-position="top" aria-label="Linear-Regression-Sxx,Syy-Variances-Sigma-MSE-r > Estimating $ sigma {2}$ and MSE" data-href="Linear-Regression-Sxx,Syy-Variances-Sigma-MSE-r#Estimating $ sigma {2}$ and MSE" href="\zettelkasten\literature-notes\linear-regression-sxx,syy-variances-sigma-mse-r.html#Estimating_$_sigma_{2}$_and_MSE" class="internal-link" target="_self" rel="noopener">MSE and the variance</a>.<br><br><br><a data-href="College Regression Analysis" href="\zettelkasten\hub-notes\college-regression-analysis.html" class="internal-link" target="_self" rel="noopener">College Regression Analysis</a>]]></description><link>zettelkasten\literature-notes\linear-regression-confidence-interval-for-parameter.html</link><guid isPermaLink="false">Zettelkasten/Literature Notes/Linear-Regression-Confidence-interval-for-parameter.md</guid><pubDate>Tue, 02 Apr 2024 20:49:18 GMT</pubDate><enclosure url="lib\media\pasted-image-20240402224811.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240402224811.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Linear-Regression-Parameter-Distribution]]></title><description><![CDATA[ 
 <br>Tags: <a data-href="Regression" href="\Regression" class="internal-link" target="_self" rel="noopener">Regression</a> <a data-href="Computer Science" href="\Computer Science" class="internal-link" target="_self" rel="noopener">Computer Science</a> <a data-href="Math" href="\Math" class="internal-link" target="_self" rel="noopener">Math</a> <a data-href="Statistics" href="\Statistics" class="internal-link" target="_self" rel="noopener">Statistics</a> <a data-href="Data-Science" href="\Data-Science" class="internal-link" target="_self" rel="noopener">Data-Science</a><br><br>Reminder

Refer to: <a data-tooltip-position="top" aria-label="Least-Square-Estimation-Linear-Regression > $S_{xx}$ and $S_{xy}$ can be written as" data-href="Least-Square-Estimation-Linear-Regression#$S_{xx}$ and $S_{xy}$ can be written as" href="\zettelkasten\literature-notes\least-square-estimation-linear-regression.html#$S_{xx}$_and_$S_{xy}$_can_be_written_as" class="internal-link" target="_self" rel="noopener">Sxx &amp; Sxy Different forms</a>
<br><br><br>Pretty intuitive, this is the equation of the regression line. Where do you expect  to be? on the line that we got. <br><br><br>we can see that y is independent but not identically distributed, that is because the equation for the mean has a  which is different in each y making each point have a different mean ;and thus, a different distribution.<br>Note:  is fixed not a random variable so it has no distribution, i.e.  it is fixed in the sense that is taken to be known values. Thus, we treat x as a constant.<br><br><br><br> proof:
<br>proof:
<br>
<br>for  proof, refer to:&nbsp;<a data-tooltip-position="top" aria-label="app://obsidian.md/Least-Square-Estimation-Linear-Regression#$S_%7Bxx%7D$%20and%20$S_%7Bxy%7D$%20can%20be%20written%20as" rel="noopener" class="external-link" href="\Least-Square-Estimation-Linear-Regression#$S_{xx}$ and $S_{xy}$ can be written as" target="_blank">Sxx &amp; Sxy Different forms</a>
<br>proof:
<br><br><br>Thus,  is an unbiased estimator.<br><br><br><br><br>reminder: <br><br> is an unbiased estimator<br>Reminder
when subtracted:

<br><br>For the cov=0 proof, refer to <a data-tooltip-position="top" aria-label="https://stats.stackexchange.com/a/64217" rel="noopener" class="external-link" href="https://stats.stackexchange.com/a/64217" target="_blank">This</a><br><br><br><br><a data-href="College Regression Analysis" href="\zettelkasten\hub-notes\college-regression-analysis.html" class="internal-link" target="_self" rel="noopener">College Regression Analysis</a>]]></description><link>zettelkasten\literature-notes\linear-regression-parameter-distribution.html</link><guid isPermaLink="false">Zettelkasten/Literature Notes/Linear-Regression-Parameter-Distribution.md</guid><pubDate>Tue, 02 Apr 2024 10:40:33 GMT</pubDate></item><item><title><![CDATA[Linear-Regression-SSE-SSR-SST]]></title><description><![CDATA[ 
 <br>Tags: <a data-href="Regression" href="\Regression" class="internal-link" target="_self" rel="noopener">Regression</a> <a data-href="Computer Science" href="\Computer Science" class="internal-link" target="_self" rel="noopener">Computer Science</a> <a data-href="Math" href="\Math" class="internal-link" target="_self" rel="noopener">Math</a><br><br><img alt="Pasted image 20240329014928.png" src="\lib\media\pasted-image-20240329014928.png">
The total variance in our model can be explained by:<br>
<br>Variance explained by the feature (x)
<br>Variance still unexplained<br>
These can be expressed as Sum of Squares total (SST):
<br>SSR: Sum of squares due to Regression
<br>SSE: Sum of squares due to Error<br>
Where: SST= SSR+SSE<br>
<img alt="Pasted image 20240329015755.png" src="\lib\media\pasted-image-20240329015755.png" style="width: 500px; max-width: 100%;">


<br><br>proof:<br><br><br>Since we know that SSE=  in,  and that . Substituting these values in SST = SSE + SSR we get:<br><br><br>we first add  (=0) to the equation<br><br><br><br><a data-href="College Regression Analysis" href="\zettelkasten\hub-notes\college-regression-analysis.html" class="internal-link" target="_self" rel="noopener">College Regression Analysis</a>]]></description><link>zettelkasten\literature-notes\linear-regression-sse-ssr-sst.html</link><guid isPermaLink="false">Zettelkasten/Literature Notes/Linear-Regression-SSE-SSR-SST.md</guid><pubDate>Tue, 02 Apr 2024 10:40:20 GMT</pubDate><enclosure url="lib\media\pasted-image-20240329014928.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240329014928.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Linear-Regression-Variances-Sigma-MSE]]></title><description><![CDATA[ 
 <br>Tags: <a data-href="Regression" href="\Regression" class="internal-link" target="_self" rel="noopener">Regression</a> <a data-href="Computer Science" href="\Computer Science" class="internal-link" target="_self" rel="noopener">Computer Science</a> <a data-href="Math" href="\Math" class="internal-link" target="_self" rel="noopener">Math</a><br><br><br>Sample Variance rule

<br><br>Sample Covariance Rule

<br><br><br>Correlation Coefficient   Rule

<br><br><br><br><br>From Probability 2:  is an unbiased estimator of 

<br>Since we estimated 2 parameters  we will estimate  with d.f. = n-2:<br><br>Thus:
<br><br><br><a data-href="College Regression Analysis" href="\zettelkasten\hub-notes\college-regression-analysis.html" class="internal-link" target="_self" rel="noopener">College Regression Analysis</a>]]></description><link>zettelkasten\literature-notes\linear-regression-sxx,syy-variances-sigma-mse-r.html</link><guid isPermaLink="false">Zettelkasten/Literature Notes/Linear-Regression-Sxx,Syy-Variances-Sigma-MSE-r.md</guid><pubDate>Tue, 02 Apr 2024 10:40:27 GMT</pubDate></item></channel></rss>